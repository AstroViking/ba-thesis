<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Comparison | Performance of Univariate Kernel Density Estimation methods in TensorFlow</title>
  <meta name="description" content="5 Comparison | Performance of Univariate Kernel Density Estimation methods in TensorFlow" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Comparison | Performance of Univariate Kernel Density Estimation methods in TensorFlow" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Comparison | Performance of Univariate Kernel Density Estimation methods in TensorFlow" />
  
  
  

<meta name="author" content="Marc Steiner" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="tensorflowImplementation.html"/>
<link rel="next" href="summary.html"/>
<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#kernel-density-estimation"><i class="fa fa-check"></i><b>1.1</b> Kernel Density Estimation</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#zfit-and-tensorflow"><i class="fa fa-check"></i><b>1.2</b> zfit and TensorFlow</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#purpose-of-this-thesis"><i class="fa fa-check"></i><b>1.3</b> Purpose of this thesis</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#introduction-univariate"><i class="fa fa-check"></i><b>1.4</b> Univariate case</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html"><i class="fa fa-check"></i><b>2</b> Theory</a>
<ul>
<li class="chapter" data-level="2.1" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html#exact-kernel-density-estimation"><i class="fa fa-check"></i><b>2.1</b> Exact Kernel Density Estimation</a></li>
<li class="chapter" data-level="2.2" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html#simple-and-linear-binning"><i class="fa fa-check"></i><b>2.2</b> Simple and linear binning</a></li>
<li class="chapter" data-level="2.3" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html#using-convolution-and-the-fast-fourier-transform"><i class="fa fa-check"></i><b>2.3</b> Using convolution and the Fast Fourier Transform</a></li>
<li class="chapter" data-level="2.4" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html#improved-sheather-jones-algorithm"><i class="fa fa-check"></i><b>2.4</b> Improved Sheather-Jones Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="currentState.html"><a href="currentState.html"><i class="fa fa-check"></i><b>3</b> Current state of the art</a></li>
<li class="chapter" data-level="4" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html"><i class="fa fa-check"></i><b>4</b> Implementation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#exact-kernel-density-estimation-1"><i class="fa fa-check"></i><b>4.1</b> Exact Kernel Density Estimation</a></li>
<li class="chapter" data-level="4.2" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#simple-and-linear-binning-1"><i class="fa fa-check"></i><b>4.2</b> Simple and linear Binning</a></li>
<li class="chapter" data-level="4.3" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#using-convolution-and-the-fast-fourier-transform-1"><i class="fa fa-check"></i><b>4.3</b> Using convolution and the Fast Fourier Transform</a></li>
<li class="chapter" data-level="4.4" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#improved-sheather-jones-algorithm-1"><i class="fa fa-check"></i><b>4.4</b> Improved Sheather Jones Algorithm</a></li>
<li class="chapter" data-level="4.5" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#source-code"><i class="fa fa-check"></i><b>4.5</b> Source Code</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="comparison.html"><a href="comparison.html"><i class="fa fa-check"></i><b>5</b> Comparison</a>
<ul>
<li class="chapter" data-level="5.1" data-path="comparison.html"><a href="comparison.html#benchmark-setup"><i class="fa fa-check"></i><b>5.1</b> Benchmark setup</a></li>
<li class="chapter" data-level="5.2" data-path="comparison.html"><a href="comparison.html#differences-of-exact-binned-fft-and-isj-implementations"><i class="fa fa-check"></i><b>5.2</b> Differences of Exact, Binned, FFT and ISJ implementations</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="comparison.html"><a href="comparison.html#accuracy"><i class="fa fa-check"></i><b>5.2.1</b> Accuracy</a></li>
<li class="chapter" data-level="5.2.2" data-path="comparison.html"><a href="comparison.html#runtime"><i class="fa fa-check"></i><b>5.2.2</b> Runtime</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="comparison.html"><a href="comparison.html#comparison-to-kdepy-on-cpu"><i class="fa fa-check"></i><b>5.3</b> Comparison to KDEpy on CPU</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="comparison.html"><a href="comparison.html#accuracy-1"><i class="fa fa-check"></i><b>5.3.1</b> Accuracy</a></li>
<li class="chapter" data-level="5.3.2" data-path="comparison.html"><a href="comparison.html#runtime-1"><i class="fa fa-check"></i><b>5.3.2</b> Runtime</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="comparison.html"><a href="comparison.html#comparison-to-kdepy-on-gpu"><i class="fa fa-check"></i><b>5.4</b> Comparison to KDEpy on GPU</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="comparison.html"><a href="comparison.html#accuracy-2"><i class="fa fa-check"></i><b>5.4.1</b> Accuracy</a></li>
<li class="chapter" data-level="5.4.2" data-path="comparison.html"><a href="comparison.html#runtime-2"><i class="fa fa-check"></i><b>5.4.2</b> Runtime</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>6</b> Summary</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="presentation/index.html" target="_blank">Presentation</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Performance of Univariate Kernel Density Estimation methods in TensorFlow</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="comparison" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Comparison</h1>
<p>To show the efficiency and performance of the different kernel density estimation methods implemented with TensorFlow a benchmarking suite was developed. It consists of three parts: a collection of distributions to use, a collection of methods to compare and a runner module that implements helper methods to execute the methods to test against the different distributions and plot the generated datasets nicely.</p>
<div id="benchmark-setup" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Benchmark setup</h2>
<p>To compare the different implementations multiple popular test distributions mentioned in Wand et al.<span class="citation"><sup><a href="references.html#ref-wand1994kernel" role="doc-biblioref">11</a></sup></span> were used. A simple normal distribution, a simple uniform distribution, a bimodal distribution comprised of two normals, a skewed bimodal distribution, a claw distribution that has spikes and one called asymmetric double claw that has different sized spikes left and right. The data is sampled randomly from each test distribution.</p>
<p>All comparisons were made using a standard Gaussian Kernel. Although all loc-scale family distributions of TensorFlow Probability may be used for the new implementation proposed in this paper, the Gaussian kernel is the most used one and provides best reference to compare different implementations against eachother.</p>
<p>For all implementations that use binning <span class="math inline">\(2^10 = 1024\)</span> bins were used. This is the default used in KDEpy, a power of <span class="math inline">\(2\)</span> (which is favorable for FFT based algorithms), results in an exact kernel density calculation for the lowest sample size used (<span class="math inline">\(10^3\)</span>) but also yields results with high accuracy for the highest sample size used (<span class="math inline">\(10^8\)</span>).</p>
<div class="figure"><span id="fig:showDistributions"></span>
<img src="thesis_files/figure-html/showDistributions-1.png" alt="Distributions used for the comparisons" width="672" />
<p class="caption">
Figure 5.1: Distributions used for the comparisons
</p>
</div>
</div>
<div id="differences-of-exact-binned-fft-and-isj-implementations" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Differences of Exact, Binned, FFT and ISJ implementations</h2>
<p>First, the exact kernel density estimation implementation is compared against linearly binned, FFT and ISJ implementations run on a Macbook Pro 2013 Retina using the CPU.</p>
<p>The sample sizes lie in the range of <span class="math inline">\(10^3\)</span> to <span class="math inline">\(10^4\)</span>. The number of samples is restricted because calculating the exact kernel density estimation for more than <span class="math inline">\(10^4\)</span> kernels is computationally unfeasible (larger datasets would lead to an exponentially larger runtime).</p>
<div id="accuracy" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Accuracy</h3>
<p>Plotted below are the comparisons for sample size of <span class="math inline">\(10^4\)</span>.</p>
<div class="figure"><span id="fig:compareSimpleBinnedFFTISJEstimations"></span>
<img src="thesis_files/figure-html/compareSimpleBinnedFFTISJEstimations-1.png" alt="Comparison between the four algorithms 'Exact', 'Binned', 'FFT' and 'ISJ' with $N=10^4$ sample points" width="672" />
<p class="caption">
Figure 5.2: Comparison between the four algorithms ‘Exact,’ ‘Binned,’ ‘FFT’ and ‘ISJ’ with <span class="math inline">\(N=10^4\)</span> sample points
</p>
</div>
<p>It becomes obvious that the ISJ approach is especially favorable for complicated spiky distributions like the two bottom ones. We can see this in more detail below. Using the ISJ the integrated square error (ISE) is an order of magnitude lower.</p>
<pre><code>## &lt;Figure size 700x500 with 1 Axes&gt;</code></pre>
The calculated integrated square errors for all distributions are as follows:
<div class="figure"><span id="fig:compareSimpleBinnedFFTISJErrors"></span>
<img src="thesis_files/figure-html/compareSimpleBinnedFFTISJErrors-1.png" alt="Integrated square errors (ISE) for the four algorithms 'Exact', 'Binned', 'FFT' and 'ISJ' with $N=10^4$ sample points" width="672" />
<p class="caption">
Figure 5.3: Integrated square errors (ISE) for the four algorithms ‘Exact,’ ‘Binned,’ ‘FFT’ and ‘ISJ’ with <span class="math inline">\(N=10^4\)</span> sample points
</p>
</div>
</div>
<div id="runtime" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Runtime</h3>
<div class="figure"><span id="fig:compareSimpleBinnedFFTISJRuntimeInstantiation"></span>
<img src="thesis_files/figure-html/compareSimpleBinnedFFTISJRuntimeInstantiation-1.png" alt="Runtime difference of the instantiaton step between the four algorithms 'Exact', 'Binned', 'FFT' and 'ISJ'" width="672" />
<p class="caption">
Figure 5.4: Runtime difference of the instantiaton step between the four algorithms ‘Exact,’ ‘Binned,’ ‘FFT’ and ‘ISJ’
</p>
</div>
<p>Although the ISJ and the FFT based approach are slower to instantiate, they are significantly faster for larger datasets during the PDF evaluation step.</p>
<div class="figure"><span id="fig:compareSimpleBinnedFFTISJRuntimePDF"></span>
<img src="thesis_files/figure-html/compareSimpleBinnedFFTISJRuntimePDF-1.png" alt="Runtime difference of the evaluation step between the four algorithms 'Exact', 'Binned', 'FFT' and 'ISJ'" width="672" />
<p class="caption">
Figure 5.5: Runtime difference of the evaluation step between the four algorithms ‘Exact,’ ‘Binned,’ ‘FFT’ and ‘ISJ’
</p>
</div>
</div>
</div>
<div id="comparison-to-kdepy-on-cpu" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Comparison to KDEpy on CPU</h2>
<p>The number of samples per test distribution is in the range of <span class="math inline">\(10^3\)</span> - <span class="math inline">\(10^8\)</span>. Larger datasets can be used, since the exact kernel density estimation is not part of the comparison.</p>
<div id="accuracy-1" class="section level3" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Accuracy</h3>
<p>Plotted below are the comparisons for sample size of <span class="math inline">\(10^4\)</span>.</p>
<div class="figure"><span id="fig:compareZfitKDEpyEstimations"></span>
<img src="thesis_files/figure-html/compareZfitKDEpyEstimations-1.png" alt="Comparison between the newly proposed algorithms 'Binned', 'FFT', 'ISJ' and the FFT based implementation in KDEpy with $N=10^4$ sample points" width="672" />
<p class="caption">
Figure 5.6: Comparison between the newly proposed algorithms ‘Binned,’ ‘FFT,’ ‘ISJ’ and the FFT based implementation in KDEpy with <span class="math inline">\(N=10^4\)</span> sample points
</p>
</div>
<p>The different methods behave the same as the reference implementation in KDEpy, again with the exception of the ISJ algorithm, which works better for spiky distributions.</p>
<p>The integrated square errors below, we can see that they are in the same order of magnitude for all implementations tested, except for the ISJ method on the Claw distribution. Here the <span class="math inline">\(ISE\)</span> is an order of magnitude lower.</p>
<div class="figure"><span id="fig:compareZfitKDEpyErrors"></span>
<img src="thesis_files/figure-html/compareZfitKDEpyErrors-1.png" alt="Integrated square errors (ISE) for the newly proposed algorithms 'Binned', 'FFT', 'ISJ' and the FFT based implementation in KDEpy with $N=10^4$ sample points" width="672" />
<p class="caption">
Figure 5.7: Integrated square errors (ISE) for the newly proposed algorithms ‘Binned,’ ‘FFT,’ ‘ISJ’ and the FFT based implementation in KDEpy with <span class="math inline">\(N=10^4\)</span> sample points
</p>
</div>
<p>Additionally it can be shown that <span class="math inline">\(2^10\)</span> bins capture the underlying distributions with high accuracy even for a sample size of <span class="math inline">\(10^8\)</span>.</p>
<div class="figure"><span id="fig:compareZfitKDEpyEstimations8"></span>
<img src="thesis_files/figure-html/compareZfitKDEpyEstimations8-1.png" alt="Comparison between the newly proposed algorithms 'Binned', 'FFT', 'ISJ' and the FFT based implementation in KDEpy with $N=10^8$ sample points" width="672" />
<p class="caption">
Figure 5.8: Comparison between the newly proposed algorithms ‘Binned,’ ‘FFT,’ ‘ISJ’ and the FFT based implementation in KDEpy with <span class="math inline">\(N=10^8\)</span> sample points
</p>
</div>
</div>
<div id="runtime-1" class="section level3" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> Runtime</h3>
<p>During the instantiation step the newly proposed binned, FFT, and ISJ methods are slower than KDEpy’s FFT method by one or two orders of magnitude. This is predictable since calculating the TensorFlow graph generates some overhead.</p>
<div class="figure"><span id="fig:compareZfitKDEpyRuntimeInstantiation"></span>
<img src="thesis_files/figure-html/compareZfitKDEpyRuntimeInstantiation-1.png" alt="Runtime difference of the instantiaton step between the newly proposed algorithms 'Binned', 'FFT', 'ISJ' and the FFT based implementation in KDEpy" width="672" />
<p class="caption">
Figure 5.9: Runtime difference of the instantiaton step between the newly proposed algorithms ‘Binned,’ ‘FFT,’ ‘ISJ’ and the FFT based implementation in KDEpy
</p>
</div>
<p>In many practical situtations in high energy physics however, generating the TensorFlow graph and the density distribution has to be done only once and the pdf is evaluated repeatedly. Therefore in such cases the PDF evaluation step is of higher importance. We can see, that once the initial graph is built, evaluating the PDF for different values of <span class="math inline">\(x\)</span> is nearly constant instead increasing exponentially as in the case of KDEpy’s FFT method.</p>
<div class="figure"><span id="fig:compareZfitKDEpyRuntimePDF"></span>
<img src="thesis_files/figure-html/compareZfitKDEpyRuntimePDF-1.png" alt="Runtime difference of the evaluation step between the newly proposed algorithms 'Binned', 'FFT', 'ISJ' and the FFT based implementation in KDEpy" width="672" />
<p class="caption">
Figure 5.10: Runtime difference of the evaluation step between the newly proposed algorithms ‘Binned,’ ‘FFT,’ ‘ISJ’ and the FFT based implementation in KDEpy
</p>
</div>
</div>
</div>
<div id="comparison-to-kdepy-on-gpu" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Comparison to KDEpy on GPU</h2>
<p>The number of samples per test distribution is again in the range of <span class="math inline">\(10^3\)</span> - <span class="math inline">\(10^8\)</span>. All computations were executed using two Tesla P100 GPU’s on the openSUSE Leap operating system.</p>
<div id="accuracy-2" class="section level3" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Accuracy</h3>
<p>Plotted below are the comparisons for sample size of <span class="math inline">\(10^4\)</span>.</p>
<div class="figure"><span id="fig:compareZfitKDEpyEstimationsGPU"></span>
<img src="thesis_files/figure-html/compareZfitKDEpyEstimationsGPU-1.png" alt="Comparison between the newly proposed algorithms 'Binned', 'FFT', 'ISJ' and the FFT based implementation in KDEpy with $N=10^4$ sample points (run on GPU)" width="672" />
<p class="caption">
Figure 5.11: Comparison between the newly proposed algorithms ‘Binned,’ ‘FFT,’ ‘ISJ’ and the FFT based implementation in KDEpy with <span class="math inline">\(N=10^4\)</span> sample points (run on GPU)
</p>
</div>
<div class="figure"><span id="fig:compareZfitKDEpyErrorsGPU"></span>
<img src="thesis_files/figure-html/compareZfitKDEpyErrorsGPU-1.png" alt="Integrated square errors (ISE) for the newly proposed algorithms 'Binned', 'FFT', 'ISJ' and the FFT based implementation in KDEpy with $N=10^4$ sample points (run on GPU)" width="672" />
<p class="caption">
Figure 5.12: Integrated square errors (ISE) for the newly proposed algorithms ‘Binned,’ ‘FFT,’ ‘ISJ’ and the FFT based implementation in KDEpy with <span class="math inline">\(N=10^4\)</span> sample points (run on GPU)
</p>
</div>
<p>Looking at the integrated square errors, we see the same behavior as for the comparison on CPU.</p>
<div class="figure"><span id="fig:compareZfitKDEpyErrorsGPU8"></span>
<img src="thesis_files/figure-html/compareZfitKDEpyErrorsGPU8-1.png" alt="Integrated square errors (ISE) for the newly proposed algorithms 'Binned', 'FFT', 'ISJ' and the FFT based implementation in KDEpy with $N=10^8$ sample points (run on GPU)" width="672" />
<p class="caption">
Figure 5.13: Integrated square errors (ISE) for the newly proposed algorithms ‘Binned,’ ‘FFT,’ ‘ISJ’ and the FFT based implementation in KDEpy with <span class="math inline">\(N=10^8\)</span> sample points (run on GPU)
</p>
</div>
<p>For larger datasets <span class="math inline">\(&gt;10^8\)</span> the accuracy of all the newly proposed methods is higher than for KDEpy’s FFT method.</p>
</div>
<div id="runtime-2" class="section level3" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Runtime</h3>
<div class="figure"><span id="fig:compareZfitKDEpyRuntimeInstantiationGPU"></span>
<img src="thesis_files/figure-html/compareZfitKDEpyRuntimeInstantiationGPU-1.png" alt="Runtime difference of the instantiaton step between the newly proposed algorithms 'Binned', 'FFT', 'ISJ' and the FFT based implementation in KDEpy (run on GPU)" width="672" />
<p class="caption">
Figure 5.14: Runtime difference of the instantiaton step between the newly proposed algorithms ‘Binned,’ ‘FFT,’ ‘ISJ’ and the FFT based implementation in KDEpy (run on GPU)
</p>
</div>
<p>The instantiation of the newly proposed implementations runs faster on the GPU than the CPU. This is no surprise as many operations in TensorFlow benefit from the parallel processing on the GPU. For a high number of sample points the newly proposed binned as well as the newly proposed FFT implementation are instantiated nearly as fast as KDEpy’s FFT implementation if run on a GPU.</p>
<div class="figure"><span id="fig:compareZfitKDEpyRuntimePDFGPU"></span>
<img src="thesis_files/figure-html/compareZfitKDEpyRuntimePDFGPU-1.png" alt="Runtime difference of the evaluation step between the newly proposed algorithms 'Binned', 'FFT', 'ISJ' and the FFT based implementation in KDEpy (run on GPU)" width="672" />
<p class="caption">
Figure 5.15: Runtime difference of the evaluation step between the newly proposed algorithms ‘Binned,’ ‘FFT,’ ‘ISJ’ and the FFT based implementation in KDEpy (run on GPU)
</p>
</div>
<p>The runtime of the PDF evaluation step does not differ much from the one seen on the CPU. All new methods are evaluated in near constant time.</p>
<div class="figure"><span id="fig:compareZfitKDEpyRuntimeTotal"></span>
<img src="thesis_files/figure-html/compareZfitKDEpyRuntimeTotal-1.png" alt="Runtime difference of the total calculation (instantiation and evaluation step) between the newly proposed algorithms 'Binned', 'FFT', 'ISJ' and the FFT based implementation in KDEpy (run on GPU)" width="672" />
<p class="caption">
Figure 5.16: Runtime difference of the total calculation (instantiation and evaluation step) between the newly proposed algorithms ‘Binned,’ ‘FFT,’ ‘ISJ’ and the FFT based implementation in KDEpy (run on GPU)
</p>
</div>
<p>For larger datasets ($&gt;10^8) even the total runtime (instantiation and PDF evaluation combined) is faster than KDEpy’s FFT method.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tensorflowImplementation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="summary.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/AstroViking/ba-thesis/edit/master/chapters/05-comparison.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/AstroViking/ba-thesis/blob/master/chapters/05-comparison.Rmd",
"text": null
},
"download": ["thesis.pdf", "thesis.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
