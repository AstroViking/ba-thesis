<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Implementation | Performance of univariate kernel density estimation methods in TensorFlow</title>
  <meta name="description" content="4 Implementation | Performance of univariate kernel density estimation methods in TensorFlow" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Implementation | Performance of univariate kernel density estimation methods in TensorFlow" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Implementation | Performance of univariate kernel density estimation methods in TensorFlow" />
  
  
  

<meta name="author" content="Marc Steiner" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="currentState.html"/>
<link rel="next" href="comparison.html"/>
<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#purpose-of-this-thesis"><i class="fa fa-check"></i><b>1.1</b> Purpose of this thesis</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#kernel-density-estimation"><i class="fa fa-check"></i><b>1.2</b> kernel density estimation</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#zfit-and-tensorflow"><i class="fa fa-check"></i><b>1.3</b> zfit and TensorFlow</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#introduction-univariate"><i class="fa fa-check"></i><b>1.4</b> Univariate case</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html"><i class="fa fa-check"></i><b>2</b> Theory</a>
<ul>
<li class="chapter" data-level="2.1" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html#exact-kernel-density-estimation"><i class="fa fa-check"></i><b>2.1</b> Exact kernel density estimation</a></li>
<li class="chapter" data-level="2.2" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html#binningTheory"><i class="fa fa-check"></i><b>2.2</b> Binning</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html#simple-binning"><i class="fa fa-check"></i><b>2.2.1</b> Simple binning</a></li>
<li class="chapter" data-level="2.2.2" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html#linear-binning"><i class="fa fa-check"></i><b>2.2.2</b> Linear binning</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html#fftTheory"><i class="fa fa-check"></i><b>2.3</b> Using convolution and the Fast Fourier Transform</a></li>
<li class="chapter" data-level="2.4" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html#isjTheory"><i class="fa fa-check"></i><b>2.4</b> Improved Sheather-Jones Algorithm</a></li>
<li class="chapter" data-level="2.5" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html#hofmeyrTheory"><i class="fa fa-check"></i><b>2.5</b> Using specialized kernel functions and their series expansion</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="currentState.html"><a href="currentState.html"><i class="fa fa-check"></i><b>3</b> Current state of the art</a></li>
<li class="chapter" data-level="4" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html"><i class="fa fa-check"></i><b>4</b> Implementation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#advantages-of-using-zfit-tensorflow"><i class="fa fa-check"></i><b>4.1</b> Advantages of using zfit TensorFlow</a></li>
<li class="chapter" data-level="4.2" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#exact-univariate-kernel-density-estimation"><i class="fa fa-check"></i><b>4.2</b> Exact univariate kernel density estimation</a></li>
<li class="chapter" data-level="4.3" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#binned-method"><i class="fa fa-check"></i><b>4.3</b> Binned method</a></li>
<li class="chapter" data-level="4.4" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#fft-based-method"><i class="fa fa-check"></i><b>4.4</b> FFT based method</a></li>
<li class="chapter" data-level="4.5" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#isjMethod"><i class="fa fa-check"></i><b>4.5</b> ISJ based method</a></li>
<li class="chapter" data-level="4.6" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#hofmeyrMethod"><i class="fa fa-check"></i><b>4.6</b> Specialized kernel method</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="comparison.html"><a href="comparison.html"><i class="fa fa-check"></i><b>5</b> Comparison</a>
<ul>
<li class="chapter" data-level="5.1" data-path="comparison.html"><a href="comparison.html#benchmark-setup"><i class="fa fa-check"></i><b>5.1</b> Benchmark setup</a></li>
<li class="chapter" data-level="5.2" data-path="comparison.html"><a href="comparison.html#differences-of-exact-binned-fft-isj-and-hofmeyr-implementations"><i class="fa fa-check"></i><b>5.2</b> Differences of Exact, Binned, FFT, ISJ and Hofmeyr implementations</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="comparison.html"><a href="comparison.html#accuracy"><i class="fa fa-check"></i><b>5.2.1</b> Accuracy</a></li>
<li class="chapter" data-level="5.2.2" data-path="comparison.html"><a href="comparison.html#runtime"><i class="fa fa-check"></i><b>5.2.2</b> Runtime</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="comparison.html"><a href="comparison.html#comparison-to-kdepy"><i class="fa fa-check"></i><b>5.3</b> Comparison to KDEpy</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="comparison.html"><a href="comparison.html#accuracy-1"><i class="fa fa-check"></i><b>5.3.1</b> Accuracy</a></li>
<li class="chapter" data-level="5.3.2" data-path="comparison.html"><a href="comparison.html#runtime-1"><i class="fa fa-check"></i><b>5.3.2</b> Runtime</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="comparison.html"><a href="comparison.html#comparison-to-kdepy-on-gpu"><i class="fa fa-check"></i><b>5.4</b> Comparison to KDEpy on GPU</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="comparison.html"><a href="comparison.html#runtime-2"><i class="fa fa-check"></i><b>5.4.1</b> Runtime</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>6</b> Summary</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a>
<ul>
<li class="chapter" data-level="6.1" data-path="appendix.html"><a href="appendix.html#source-code"><i class="fa fa-check"></i><b>6.1</b> Source Code</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="presentation/index.html" target="_blank">Presentation</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Performance of univariate kernel density estimation methods in TensorFlow</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tensorflowImplementation" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Implementation</h1>
<p>In addition to the rather simple case of an exact univariate kernel density estimation (henceforth called <code>ZfitExact</code>), four conceptually different novel implementations in zfit and TensorFlow are proposed. A method based on simple or linear binning (called <code>ZfitBinned</code>), a method using the FFT algorithm (called <code>ZfitFFT</code>), a method based on the improved Sheather Jones algorithm (called <code>ZfitISJ</code>) and lastly a method based on Hofmeyr’s method of using a specialized kernel of the form <span class="math inline">\(poly(x)\cdot\exp(x)\)</span> (called <code>ZfitHofmeyr</code>) and recursive computation of the bases needed to calculate the kernel density estimations as linear combination. All methods are implemented for the univariate case only.</p>
<p>Important to note is that for <code>ZfitISJ</code> and <code>ZfitFFT</code> simple or linear binning is preliminary.</p>
<div id="advantages-of-using-zfit-tensorflow" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Advantages of using zfit TensorFlow</h2>
<p>The benefit of using zfit, which is based on TensorFlow is that it (and TensorFlow) is optimized for parallel processing and CPU as well as GPU processing. TensorFlow uses graph based computation, which means that it generates a computational graph of all operations to be done and their order, before actually executing the computation. This has to key advantages.</p>
<p>First it allows TensorFlow to act as a kind of Compiler and optimize the code before running and schedule graph branches, that are independent of each other to different processors to be executed in parallel. Operations in TensorFlow are often implemented twice, once for CPU and once for GPU to make use of the different environments available on each processor type. Also, similarly to NumPy<span class="citation"><sup><a href="references.html#ref-harrisArrayProgrammingNumPy2020" role="doc-biblioref">9</a></sup></span>, TensorFlow’s underlying operations are programmed in C++ and therefore benefit from static typing and compile time optimization.</p>
<p>Secondly it allows fore automatic differentiation, meaning that every TensorFlow operation defines its own derivative. Using the chain rule, TensorFlow can then automatically compute the gradient of the whole program, which is especially useful for non-parametric fitting (i.e. gradient descent computations in function approximations using a neural network).</p>
</div>
<div id="exact-univariate-kernel-density-estimation" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Exact univariate kernel density estimation</h2>
<p>The implementation of an exact univariate kernel density estimation in TensorFlow is straightforward. As described in the original Tensorflow Probability Paper<span class="citation"><sup><a href="references.html#ref-googleTFP" role="doc-biblioref">2</a></sup></span>, a KDE can be constructed by using its <code>MixtureSameFamily</code> distribution class, given sampled <code>data</code>, their associated <code>weights</code> and bandwidth <code>h</code> as follows</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="tensorflowImplementation.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-2"><a href="tensorflowImplementation.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow_probability <span class="im">import</span> distributions <span class="im">as</span> tfd</span>
<span id="cb1-3"><a href="tensorflowImplementation.html#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="tensorflowImplementation.html#cb1-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [...]</span>
<span id="cb1-5"><a href="tensorflowImplementation.html#cb1-5" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> [...]</span>
<span id="cb1-6"><a href="tensorflowImplementation.html#cb1-6" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> ...</span>
<span id="cb1-7"><a href="tensorflowImplementation.html#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="tensorflowImplementation.html#cb1-8" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> <span class="kw">lambda</span> x: tfd.Independent(tfd.Normal(loc<span class="op">=</span>x, scale<span class="op">=</span>h))</span>
<span id="cb1-9"><a href="tensorflowImplementation.html#cb1-9" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> data.shape[<span class="dv">0</span>].value</span>
<span id="cb1-10"><a href="tensorflowImplementation.html#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="tensorflowImplementation.html#cb1-11" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> weights <span class="op">/</span> tf.reduce_sum(weights)</span>
<span id="cb1-12"><a href="tensorflowImplementation.html#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="tensorflowImplementation.html#cb1-13" aria-hidden="true" tabindex="-1"></a>kde <span class="op">=</span> tfd.MixtureSameFamily(</span>
<span id="cb1-14"><a href="tensorflowImplementation.html#cb1-14" aria-hidden="true" tabindex="-1"></a>    mixture_distribution<span class="op">=</span>tfd.Categorical(</span>
<span id="cb1-15"><a href="tensorflowImplementation.html#cb1-15" aria-hidden="true" tabindex="-1"></a>        probs<span class="op">=</span>probs),</span>
<span id="cb1-16"><a href="tensorflowImplementation.html#cb1-16" aria-hidden="true" tabindex="-1"></a>    components_distribution<span class="op">=</span>f(data))</span></code></pre></div>
<p>Interestingly, due to the smart encapsulated structure of TensorFlow Probability we can use any distribution of the loc-scale family type as a kernel as long as it follows the Distribution contract in TensorFlow Probability. If the used Kernel has only bounded support, the implementation proposed in this paper allows to specify the support upon instantiation of the class. If the Kernel has infinite support (like a Gaussian kernel for instance) a practical support estimate is calculated by searching for approximate roots with Brent’s method<span class="citation"><sup><a href="references.html#ref-brent1971algorithm" role="doc-biblioref">21</a></sup></span> implemented for TensorFlow in the python package <code>tf_quant_finance</code> by Google. This allows us to speed up the calculation as negligible contributions from far away kernels are neglected.</p>
<p>However calculating an exact kernel density estimation is not always feasible as this can take a long time with a huge collection of data points. By implementing it in TensorFlow we already get a significant speed up compared to implementations in native Python, due to TensorFlow’s advantages mentioned above. Nonetheless the computational complexity remains the same and for large data this can still make the exact KDE impractical.</p>
<p>An exact kernel density estimation using zfit called <code>ZfitExact</code> is implemented as a <code>zfit.pdf.WrapDistribution</code> class, which is zfit’s class type for wrapping TensorFlow Probability distributions.</p>
</div>
<div id="binned-method" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Binned method</h2>
<p>The method <code>ZfitBinned</code> also implements kernel density estimation as a constructed <code>MixtureSameFamily</code> distribution, however it bins the data (either simple or linearly) to an equally spaced grid and uses only the grid points weighted by their grid count as kernel locations (see section <a href="mathematicalTheory.html#binningTheory">2.2</a>).</p>
<p>Since simple binning is already implemented in TensorFlow in the function <code>tf.histogram_fixed_width</code>, the contribution of this thesis for <code>ZfitBinned</code> lies in an implementation of linear binning in TensorFlow. Implementing linear binning efficiently with TensorFlow is a bit tricky since loops should be avoided as the graph based computation is fastest with vectorized operations and loops pose a significant runtime overhead. However with some inspiration from the KDEpy package<span class="citation"><sup><a href="references.html#ref-KDEpy" role="doc-biblioref">19</a></sup></span> this can be done without using loops at all.</p>
<p>First, every data point <span class="math inline">\(x_k\)</span> is transformed to <span class="math inline">\(\tilde{x}_k\)</span> in the following way (the transformation can be vectorized)</p>
<p><span class="math display" id="eq:linbintransform">\[\begin{equation}
\tilde{x}_k = \frac{x_k - g_0}{\Delta g}
\tag{4.1}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\Delta g\)</span> is the grid spacing and <span class="math inline">\(g_0\)</span> is the left-most value of the grid.</p>
<p>Given this transformation every <span class="math inline">\(\tilde{x}_k\)</span> can then be described by an integral part <span class="math inline">\(\tilde{x}^{int}_k\)</span> (equal to its nearest left grid point index <span class="math inline">\(l\)</span> = <span class="math inline">\(x^{int}_k\)</span>) plus some fractional part <span class="math inline">\(\tilde{x}^{frac}_k\)</span> (corresponding to the additional distance between grid point <span class="math inline">\(g_l\)</span> and data point <span class="math inline">\(x_k\)</span>). The linear binning can then be solved in the following way.</p>
<p>For data points on the right side of the grid point <span class="math inline">\(g_l\)</span>: The fractional parts of the data points are summed if the integral parts equal <span class="math inline">\(l\)</span>.</p>
<p>For data points on the left side of the grid point <span class="math inline">\(g_l\)</span>: <span class="math inline">\(1\)</span> minus the fractional parts of the data points are summed if the integral parts equal <span class="math inline">\(l-1\)</span>.</p>
<p>Including the weights this looks as follows</p>
<p><span class="math display" id="eq:linbinnoloop">\[\begin{equation}
c_l = c(g_l) = \sum_{\substack{\tilde{x}^{frac}_k  \in \tilde{X}^{frac}\\l = \tilde{x}^{int}_k}} \tilde{x}^{frac}_k \cdot w_k + \sum_{\substack{\tilde{x}^{frac}_k  \in \tilde{X}^{frac}\\l = \tilde{x}^{int}_k + 1}} (1-\tilde{x}^{frac}_k) \cdot w_k
\tag{4.2}
\end{equation}\]</span></p>
<p>Left and right side sums can then be calculated efficiently with the TensorFlow function <code>tf.math.bincount</code>.</p>
<p>The binned method <code>ZfitBinned</code> is implemented in the same class definition as <code>ZfitExact</code>, the binning can be enabled by specifying a constructor argument.</p>
</div>
<div id="fft-based-method" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> FFT based method</h2>
<p>The KDE method called <code>ZfitFFT</code>, which uses the FFT based method (discussed in section <a href="mathematicalTheory.html#fftTheory">2.3</a>), is implemented as a <code>zfit.pdf.BasePdf</code> class. It is not based on TensorFlow Probability as it does not use a <code>MixtureDistribution</code> but instead calculates the estimate for the given grid points directly. To still infer values for other points in the range of <span class="math inline">\(x\)</span> <code>tfp.math.interp_regular_1d_grid</code> is used, which computes a linear interpolation of values between the grid. In TensorFlow one-dimensional discrete convolutions are efficiently implemented already if we use <code>tf.nn.conv1d</code>. In benchmarking using this method to calculate the estimate proved significantly faster than using <code>tf.signal.rfft</code> and <code>tf.signal.irfft</code> to transform, multiply and inverse transform the vectors, which is implemented as an alternative option as well.</p>
</div>
<div id="isjMethod" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> ISJ based method</h2>
<p>The method called <code>ZfitISJ</code> is also implemented as a <code>zfit.pdf.BasePdf</code> class. After using simple or linear binning to calculate the grid counts, the estimate for the grid points is calculated using the improved Sheather Jones method (discussed in section <a href="mathematicalTheory.html#isjTheory">2.4</a>).</p>
<p>To find the roots for <span class="math inline">\(\gamma^l\)</span> in equation <a href="mathematicalTheory.html#eq:hamisegamma2">(2.12)</a> Brent’s method<span class="citation"><sup><a href="references.html#ref-brent1971algorithm" role="doc-biblioref">21</a></sup></span> implemented <code>tf_quant_finance</code> is used again. To avoid loops the iterative function <span class="math inline">\(\gamma^l\)</span> is statically unrolled for <span class="math inline">\(l = 5\)</span>, since higher values would not lead to any practical differences according to the paper authors. For the Discrete Cosine Transform <code>tf.signal.dct</code> is used.</p>
</div>
<div id="hofmeyrMethod" class="section level2" number="4.6">
<h2><span class="header-section-number">4.6</span> Specialized kernel method</h2>
<p>The method called <code>ZfitHofmeyr</code> is again implemented as a <code>zfit.pdf.BasePdf</code> class. It uses specialized kernels of the form <span class="math inline">\(poly(x)\cdot\exp(x)\)</span> (as discussed in <a href="mathematicalTheory.html#hofmeyrTheory">2.5</a>).</p>
<p>However due to the recursive nature of the method, an implementation in TensorFlow directly displayed the same poor performance as using an exact kernel density estimation based on a mixture distribution. This is due to the fact, that recursive functions of this type can not be vectorized and have to be implemented using loops, which are ill-advised for TensorFlow due to its graph based paradigm. Implementing the recursion using NumPy and <code>tf.numpy_function</code> (which wraps a NumPy based Python function to create a single TensorFlow operation) was an order of magnitude faster, but still slower than all approximative methods discussed before.</p>
<p>Finally, implementing the method in C++ directly as a custom TensorFlow operation appropriately named <code>tf.hofmeyr_kde</code> yielded the competitive execution runtime expected from theory. The code for the C++ based implementation is based on the C++ code used for the author’s own R package FKSUM<span class="citation"><sup><a href="references.html#ref-hofmeyrFastKernelSmoothing2020" role="doc-biblioref">22</a></sup></span>.</p>
<p>So far the custom TensorFlow operation is only implemented as a proof of concept and poses severe limitations. Its C++ library has to be compiled for every platform specifically and it currently does not compute its own gradient and therefore does not support TensorFlow’s automatic differentiation. It is also implemented only for the CPU and does therefore not benefit of using the GPU.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="currentState.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="comparison.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/AstroViking/ba-thesis/edit/master/chapters/04-implementation.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/AstroViking/ba-thesis/blob/master/chapters/04-implementation.Rmd",
"text": null
},
"download": ["thesis.pdf", "thesis.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
