<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Implementation | Performance of Univariate Kernel Density Estimation methods in TensorFlow</title>
  <meta name="description" content="4 Implementation | Performance of Univariate Kernel Density Estimation methods in TensorFlow" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Implementation | Performance of Univariate Kernel Density Estimation methods in TensorFlow" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Implementation | Performance of Univariate Kernel Density Estimation methods in TensorFlow" />
  
  
  

<meta name="author" content="Marc Steiner" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="currentState.html"/>
<link rel="next" href="comparison.html"/>
<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#kernel-density-estimation"><i class="fa fa-check"></i><b>1.1</b> Kernel Density Estimation</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#zfit-and-tensorflow"><i class="fa fa-check"></i><b>1.2</b> zfit and TensorFlow</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#purpose-of-this-thesis"><i class="fa fa-check"></i><b>1.3</b> Purpose of this thesis</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#introduction-univariate"><i class="fa fa-check"></i><b>1.4</b> Univariate case</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html"><i class="fa fa-check"></i><b>2</b> Theory</a>
<ul>
<li class="chapter" data-level="2.1" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html#exact-kernel-density-estimation"><i class="fa fa-check"></i><b>2.1</b> Exact Kernel Density Estimation</a></li>
<li class="chapter" data-level="2.2" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html#simple-and-linear-binning"><i class="fa fa-check"></i><b>2.2</b> Simple and linear binning</a></li>
<li class="chapter" data-level="2.3" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html#using-convolution-and-the-fast-fourier-transform"><i class="fa fa-check"></i><b>2.3</b> Using convolution and the Fast Fourier Transform</a></li>
<li class="chapter" data-level="2.4" data-path="mathematicalTheory.html"><a href="mathematicalTheory.html#improved-sheather-jones-algorithm"><i class="fa fa-check"></i><b>2.4</b> Improved Sheather-Jones Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="currentState.html"><a href="currentState.html"><i class="fa fa-check"></i><b>3</b> Current state of the art</a></li>
<li class="chapter" data-level="4" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html"><i class="fa fa-check"></i><b>4</b> Implementation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#exact-kernel-density-estimation-1"><i class="fa fa-check"></i><b>4.1</b> Exact Kernel Density Estimation</a></li>
<li class="chapter" data-level="4.2" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#simple-and-linear-binning-1"><i class="fa fa-check"></i><b>4.2</b> Simple and linear Binning</a></li>
<li class="chapter" data-level="4.3" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#using-convolution-and-the-fast-fourier-transform-1"><i class="fa fa-check"></i><b>4.3</b> Using convolution and the Fast Fourier Transform</a></li>
<li class="chapter" data-level="4.4" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#improved-sheather-jones-algorithm-1"><i class="fa fa-check"></i><b>4.4</b> Improved Sheather Jones Algorithm</a></li>
<li class="chapter" data-level="4.5" data-path="tensorflowImplementation.html"><a href="tensorflowImplementation.html#source-code"><i class="fa fa-check"></i><b>4.5</b> Source Code</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="comparison.html"><a href="comparison.html"><i class="fa fa-check"></i><b>5</b> Comparison</a>
<ul>
<li class="chapter" data-level="5.1" data-path="comparison.html"><a href="comparison.html#benchmark-setup"><i class="fa fa-check"></i><b>5.1</b> Benchmark setup</a></li>
<li class="chapter" data-level="5.2" data-path="comparison.html"><a href="comparison.html#differences-of-exact-binned-fft-and-isj-implementations"><i class="fa fa-check"></i><b>5.2</b> Differences of Exact, Binned, FFT and ISJ implementations</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="comparison.html"><a href="comparison.html#accuracy"><i class="fa fa-check"></i><b>5.2.1</b> Accuracy</a></li>
<li class="chapter" data-level="5.2.2" data-path="comparison.html"><a href="comparison.html#runtime"><i class="fa fa-check"></i><b>5.2.2</b> Runtime</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="comparison.html"><a href="comparison.html#comparison-to-kdepy-on-cpu"><i class="fa fa-check"></i><b>5.3</b> Comparison to KDEpy on CPU</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="comparison.html"><a href="comparison.html#accuracy-1"><i class="fa fa-check"></i><b>5.3.1</b> Accuracy</a></li>
<li class="chapter" data-level="5.3.2" data-path="comparison.html"><a href="comparison.html#runtime-1"><i class="fa fa-check"></i><b>5.3.2</b> Runtime</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="comparison.html"><a href="comparison.html#comparison-to-kdepy-on-gpu"><i class="fa fa-check"></i><b>5.4</b> Comparison to KDEpy on GPU</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="comparison.html"><a href="comparison.html#accuracy-2"><i class="fa fa-check"></i><b>5.4.1</b> Accuracy</a></li>
<li class="chapter" data-level="5.4.2" data-path="comparison.html"><a href="comparison.html#runtime-2"><i class="fa fa-check"></i><b>5.4.2</b> Runtime</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>6</b> Summary</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="presentation/index.html" target="_blank">Presentation</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Performance of Univariate Kernel Density Estimation methods in TensorFlow</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tensorflowImplementation" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Implementation</h1>
<div id="exact-kernel-density-estimation-1" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Exact Kernel Density Estimation</h2>
<p>The implementation of an exact Kernel Density Estimation in TensorFlow is straightforward. As described in the original Tensorflow Probability Paper<span class="citation"><sup><a href="references.html#ref-googleTFP" role="doc-biblioref">17</a></sup></span>, a KDE can be constructed by using its MixtureSameFamily Distribution, given sampled <code>data</code> as follows</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="tensorflowImplementation.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow_probability <span class="im">import</span> distributions <span class="im">as</span> tfd</span>
<span id="cb1-2"><a href="tensorflowImplementation.html#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="tensorflowImplementation.html#cb1-3" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> <span class="kw">lambda</span> x: tfd.Independent(tfd.Normal(loc<span class="op">=</span>x, scale<span class="op">=</span><span class="fl">1.</span>))</span>
<span id="cb1-4"><a href="tensorflowImplementation.html#cb1-4" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> data.shape[<span class="dv">0</span>].value</span>
<span id="cb1-5"><a href="tensorflowImplementation.html#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="tensorflowImplementation.html#cb1-6" aria-hidden="true" tabindex="-1"></a>kde <span class="op">=</span> tfd.MixtureSameFamily(</span>
<span id="cb1-7"><a href="tensorflowImplementation.html#cb1-7" aria-hidden="true" tabindex="-1"></a>    mixture_distribution<span class="op">=</span>tfd.Categorical(</span>
<span id="cb1-8"><a href="tensorflowImplementation.html#cb1-8" aria-hidden="true" tabindex="-1"></a>        probs<span class="op">=</span>[<span class="dv">1</span> <span class="op">/</span> n] <span class="op">*</span> n),</span>
<span id="cb1-9"><a href="tensorflowImplementation.html#cb1-9" aria-hidden="true" tabindex="-1"></a>    components_distribution<span class="op">=</span>f(data))</span></code></pre></div>
<p>Interestingly, due to the smart encapsulated structure of TensorFlow Probability we can use any distribution of the loc-scale family type as a kernel as long as it follows the Distribution contract in TensorFlow Probability. If the used Kernel has only bounded support, the implementation proposed in this paper allows to specify the support upon instantiation of the class. If the Kernel has infinite support (like a Gaussian kernel for instance) a practical support estimate is calculated by searching for approximate roots with Brent’s method<span class="citation"><sup><a href="references.html#ref-brent1971algorithm" role="doc-biblioref">18</a></sup></span> implemented for TensorFlow in the python package <code>tf_quant_finance</code> by Google. This allows us to speed up the calculation.</p>
<p>However calculating an exact kernel density estimation is not always feasible as this can take a long time with a huge collection of data points, especially in high energy physics. By implementing it in TensorFlow we already get a significant speed up compared to implementations in native Python, since most of TensorFlow is actually implemented in C++ and the code is optimized before running. Even if the theoretical computational complexity remains the same.</p>
</div>
<div id="simple-and-linear-binning-1" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Simple and linear Binning</h2>
<p>Simple binning is already implemented in TensorFlow in the function <code>tf.histogram_fixed_width</code>.</p>
<p>Implementing linear binning efficiently with TensorFlow is a bit tricky since loops should be avoided. However with some inspiration from the KDEpy package<span class="citation"><sup><a href="references.html#ref-KDEpy" role="doc-biblioref">15</a></sup></span> this can be done without using loops at all.</p>
<p>First, every data point <span class="math inline">\(x_k\)</span> can be described by an integral part <span class="math inline">\(x^{integral}_k\)</span> (equal to its nearest left grid point number <span class="math inline">\(l\)</span> = <span class="math inline">\(x^{integral}_k\)</span>) plus some fractional part <span class="math inline">\(x^{fractional}_k\)</span> (corresponding to the additional distance between grid point <span class="math inline">\(g_l\)</span> and data point <span class="math inline">\(x_k\)</span>).</p>
<p>Then we can solve the linear binning in the following way.</p>
<p>For data points on the right side of the grid point <span class="math inline">\(g_l\)</span>: The fractional parts of the data points are summed if the integral parts equal <span class="math inline">\(l\)</span>.</p>
<p>For data points on the left side of the grid point <span class="math inline">\(g_l\)</span>: <span class="math inline">\(1\)</span> minus the fractional parts of the data points are summed if the integral parts equal <span class="math inline">\(l-1\)</span>.</p>
<p>Including the weights this looks as follows</p>
<p><span class="math display" id="eq:linbinnoloop">\[\begin{equation}
c_l = c(g_l) = \sum_{\substack{x^{fractional}_k  \in X^{fractional}\\l = x^{integral}_k}} x^{fractional}_k \cdot w_k + \sum_{\substack{x^{fractional}_k  \in X^{fractional}\\l = x^{integral}_k + 1}} (1-x^{fractional}_k) \cdot w_k
\tag{4.1}
\end{equation}\]</span></p>
<p>Left and right side sums can then be calculated efficiently with the TensorFlow function <code>tf.math.bincount</code>.</p>
</div>
<div id="using-convolution-and-the-fast-fourier-transform-1" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Using convolution and the Fast Fourier Transform</h2>
<p>In TensorFlow one-dimensional convolutions are efficiently implemented already if we use <code>tf.nn.conv1d</code>. In benchmarking using this method proved significantly faster than using <code>tf.signal.rfft</code> and <code>tf.signal.irfft</code> to transform, multiply and inverse transform the vectors, which is implemented as an alternative as well.</p>
<p>This algorithm is implemented as its own class since it does not represent a complete mixture distribution anymore but calculates just the density distribution values at the specified grid points. To still infer values for other points in the range of <span class="math inline">\(x\)</span> <code>tfp.math.interp_regular_1d_grid</code> is used, which computes a linear interpolation of values between the grid.</p>
</div>
<div id="improved-sheather-jones-algorithm-1" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> Improved Sheather Jones Algorithm</h2>
<p>To find the roots for equation <a href="mathematicalTheory.html#eq:hamisegamma2">(2.12)</a> Brent’s method<span class="citation"><sup><a href="references.html#ref-brent1971algorithm" role="doc-biblioref">18</a></sup></span> was used, which is implemented in TensorFlow in the python package <code>tf_quant_finance</code>. For the Discrete Cosine Transform <code>tf.signal.dct</code> is used.</p>
</div>
<div id="source-code" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> Source Code</h2>
<p>The source code of the newly proposed implementation can be found at [<a href="https://github.com/AstroViking/tf-kde" class="uri">https://github.com/AstroViking/tf-kde</a>].</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="currentState.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="comparison.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/AstroViking/ba-thesis/edit/master/chapters/04-implementation.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/AstroViking/ba-thesis/blob/master/chapters/04-implementation.Rmd",
"text": null
},
"download": ["thesis.pdf", "thesis.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
