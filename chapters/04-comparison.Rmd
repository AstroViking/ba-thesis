# Comparison {#comparison}

```{r, setup, echo=FALSE, eval=TRUE}
library('reticulate')
use_condaenv('ba-thesis')
```

```{python, pythonSetup, echo = FALSE, eval=TRUE}
from tf_kde.benchmark import runner
from matplotlib import pyplot as plt
import pandas as pd

distributions_to_evaluate = [
    'Gaussian',
    'Uniform',
    'Bimodal',
    'SkewedBimodal',
    'Claw',
    'AsymmetricDoubleClaw'
]

xlim = [-8, 8]

unrestricted_runtimes = pd.read_pickle('./benchmark/cpu_macbook/unrestricted_runtimes.pkl')
restricted_runtimes = pd.read_pickle('./benchmark/cpu_macbook/restricted_runtimes.pkl')

unrestricted_estimations = pd.read_pickle('./benchmark/cpu_macbook/unrestricted_estimations.pkl')
restricted_estimations = pd.read_pickle('./benchmark/cpu_macbook/restricted_estimations.pkl')

```

To show the efficiency and performance of the different kernel density estimation methods implemented with TensorFlow a benchmarking suite was developed. It consists of three parts: a collection of distributions to use, a collection of methods to compare and a runner module that implements helper methods to execute the methods to test against the different distributions and plot the generated datasets nicely.

## Benchmark setup

To compare the different implementations multiple popular test distributions mentioned in Wand et al.[@wand1994kernel] were used. A simple normal distribution, a simple uniform distribution, a bimodal distribution comprised of two normals, a skewed bimodal distribution, a claw distribution that has spikes and one called asymmetric double claw that has different sized spikes left and right. All comparisons were made using a standard Gaussian Kernel. Although all loc-scale family distributions of TensorFlow Probability may be used for the new implmentation proposed in this paper, the Gaussian kernel is the most used one and provides best reference to compare different implementations against eachother.

```{python showDistributions, echo=FALSE, eval=TRUE, fig.cap="Comparison between the four basic algorithms 'Exact', 'Binned', 'FFT', 'ISJ' with $N=10^4$ sample points"}
figure, axes = runner.plot_distributions(distributions_to_evaluate, xlim)
figure
```
## Basic implementation against Binned and FFT implementations

First we compare the basic exact kernel density estimation implementation against  binned and FFT implementations run on a Macbook Pro 2013 Retina using the CPU.

### Accuracy

For this randomly sampled data for from each test distribution is used. The number of samples per test distribution is 1000. The number of samples is restricted because calculating the exact kernel density estimation for more than 1000 kernels takes a really long time. 

For the binned, FFT and ISJ algorithms we use 256 bins each.

```{python compareSimpleBinnedFFTISJEstimations, echo=FALSE, eval=TRUE, fig.cap="Comparison between the four basic algorithms 'Exact', 'Binned', 'FFT', 'ISJ' with $N=10^4$ sample points"}
figure, axes = runner.plot_estimations(restricted_estimations, distributions_to_evaluate, 1e4, ['ZfitExact', 'ZfitBinned', 'ZfitFFT', 'ZfitISJ'])
figure
```

Here it becomes obvious that the ISJ approach is especially favorable for complicated spiky distributions like the two bottom ones. We can see this in more detail below. The integrated square error (ISE) is an order of magnitude lower.

```{python compareSimpleBinnedFFTISJEstimationClaw, echo=FALSE, eval=TRUE, fig.cap="Comparison between the four basic algorithms 'Exact', 'Binned', 'FFT', 'ISJ' with $N=10^4$ sample points on distribution 'Claw'"}
figure, axes = runner.plot_estimation(restricted_estimations, 'Claw', ['ZfitExact', 'ZfitBinned', 'ZfitFFT', 'ZfitISJ'], 1e4)
figure
```

The calculated integrated square errors for all distributions are as follows:
```{python compareSimpleBinnedFFTISJErrors, echo=FALSE, eval=TRUE, fig.cap="Integrated square errors (ISE) for the four basic algorithms 'Exact', 'Binned', 'FFT', 'ISJ' with $N=10^4$ sample points"}
figure, axes = runner.plot_integrated_square_errors(restricted_estimations, distributions_to_evaluate, 1e4, ['ZfitExact', 'ZfitBinned', 'ZfitFFT', 'ZfitISJ'])
figure
```


### Runtime

For this we use randomly sampled data for each test distribution in the range of 100 to 1000. The number of samples is restricted because larger datasets would require exponentially longer runtimes for the exact kernel density estimation.


```{python compareSimpleBinnedFFTISJRuntimeInstantiation, echo=FALSE, eval=TRUE, fig.cap="Runtime difference of the instantiaton step between the four basic algorithms 'Exact', 'Binned', 'FFT', 'ISJ'"}
figure, axes = runner.plot_runtimes(restricted_runtimes, distributions_to_evaluate, ['ZfitExact', 'ZfitBinned', 'ZfitFFT', 'ZfitISJ'], 'instantiation')
figure
```

```{python compareSimpleBinnedFFTISJRuntimePDF, echo=FALSE, eval=TRUE, fig.cap="Runtime difference of the calculation step between the four basic algorithms 'Exact', 'Binned', 'FFT', 'ISJ'"}
figure, axes = runner.plot_runtimes(restricted_runtimes, distributions_to_evaluate, ['ZfitExact', 'ZfitBinned', 'ZfitFFT', 'ZfitISJ'], 'pdf')
figure
```



## New implementation against KDEpy

### Accuracy

```{python compareZfitKDEpyEstimations, echo=FALSE, eval=TRUE, fig.cap="Comparison between the newly proposed algorithms 'Binned', 'FFT', 'ISJ' and the FFT based implementation in KDEpy with N=$10^4$ sample points"}
figure, axes = runner.plot_estimations(unrestricted_estimations, distributions_to_evaluate, 1e4, ['ZfitBinned', 'ZfitFFT', 'ZfitISJ', 'KDEpyFFT'])
figure
```

```{python compareZfitKDEpyErrors, echo=FALSE, eval=TRUE, fig.cap="Integrated square errors (ISE) for the newly proposed algorithms 'Binned', 'FFT', 'ISJ' and the FFT based implementation in KDEpy with $N=10^4$ sample points"}
figure, axes = runner.plot_integrated_square_errors(unrestricted_estimations, distributions_to_evaluate, 1e6, ['ZfitBinned', 'ZfitFFT', 'ZfitISJ', 'KDEpyFFT'])
figure
```

### Runtime

```{python compareZfitKDEpyRuntimeInstantiation, echo=FALSE, eval=TRUE, fig.cap="Runtime difference of the instantiaton step between the newly proposed algorithms 'Binned', 'FFT', 'ISJ' and the FFT based implementation in KDEpy"}
figure, axes = runner.plot_runtimes(restricted_runtimes, distributions_to_evaluate, ['ZfitExact', 'ZfitBinned', 'ZfitFFT', 'ZfitISJ', 'KDEpyFFT'], 'instantiation')
figure
```

```{python compareZfitKDEpyRuntimePDF, echo=FALSE, eval=TRUE, fig.cap="Runtime difference of the calculation step between the newly proposed algorithms 'Binned', 'FFT', 'ISJ' and the FFT based implementation in KDEpy"}
figure, axes = runner.plot_runtimes(restricted_runtimes, distributions_to_evaluate, ['ZfitExact', 'ZfitBinned', 'ZfitFFT', 'ZfitISJ', 'KDEpyFFT'], 'pdf')
figure
```

## New implementation run with GPU support

### Accuracy

### Runtime
